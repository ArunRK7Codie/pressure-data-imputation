{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAIN- Pressure","provenance":[],"mount_file_id":"1zQr1BM4jpsqKBf8KagcePVCloLXoFDwa","authorship_tag":"ABX9TyN/OdDQI0v5IUTqvn8UTY8j"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8064TOku0oDt","colab_type":"code","outputId":"5b74eb77-4d90-4b07-acfe-710d5a4d4171","executionInfo":{"status":"ok","timestamp":1581597417318,"user_tz":-330,"elapsed":2522,"user":{"displayName":"Arun Pandian R","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCH0GbqS4vWSqatMz6fQZ8tXDeKF5M-eOUqMVUPpg=s64","userId":"07597072252487905646"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["import tensorflow as tf\n","import numpy as np\n","from tqdm import tqdm\n","import pandas as pd"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Nfg98uOP0qUe","colab_type":"code","colab":{}},"source":["#%% System Parameters\n","# 1. Mini batch size\n","mb_size = 128\n","# 2. Missing rate\n","p_miss = 0.3\n","# 3. Hint rate\n","p_hint = 0.9\n","# 4. Loss Hyperparameters\n","alpha = 100\n","# 5. Train Rate\n","train_rate = 0.9\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9LSDlNSt0sw2","colab_type":"code","outputId":"ce805d2c-545b-44e0-c4f9-adbb9cde444f","executionInfo":{"status":"ok","timestamp":1581597720562,"user_tz":-330,"elapsed":2089,"user":{"displayName":"Arun Pandian R","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCH0GbqS4vWSqatMz6fQZ8tXDeKF5M-eOUqMVUPpg=s64","userId":"07597072252487905646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#%% Data\n","\n","# Data generation\n","df = pd.read_csv('/content/drive/My Drive/piv-project/pressure-data-csv.csv')\n","\n","df = df.drop(labels='Unnamed: 0', axis='columns')\n","\n","actual_df = df.copy()\n","\n","for i in ['7','24','18','29','42','47','3']:\n","  df [i] = pd.DataFrame([0 for _ in range(df[i].size)])\n","\n","\n","\n","Data = df.values #Returns Numpy Array\n","#val_Data = Data[1000:1500] # For Result Validation\n","Data = Data[1000:10000] # Sample Dataset\n","\n","print(Data.shape)\n","# Parameters\n","No = len(Data)\n","Dim = len(Data[0,:])\n","\n","# Hidden state dimensions\n","H_Dim1 = Dim\n","H_Dim2 = Dim\n","\n","# Normalization (0 to 1)\n","Min_Val = np.zeros(Dim)\n","Max_Val = np.zeros(Dim)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(9000, 50)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DImK40gS0wvB","colab_type":"code","colab":{}},"source":["for i in range(Dim):\n","    Min_Val[i] = np.min(Data[:,i])\n","    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n","    Max_Val[i] = np.max(Data[:,i])\n","    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n","\n","#%% Missing introducing\n","p_miss_vec = p_miss * np.ones((Dim,1)) \n","   \n","Missing = np.zeros((No,Dim))\n","\n","for i in range(Dim):\n","    A = np.random.uniform(0., 1., size = [len(Data),])\n","    B = A > p_miss_vec[i]\n","    Missing[:,i] = 1.*B\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRwCYi0Z009A","colab_type":"code","colab":{}},"source":["#%% Train Test Division    \n","   \n","idx = np.random.permutation(No)\n","\n","Train_No = int(No * train_rate)\n","Test_No = No - Train_No\n","    \n","# Train / Test Features\n","trainX = Data[idx[:Train_No],:]\n","testX = Data[idx[Train_No:],:]\n","FindX = Data[range(1000),:]\n","\n","# Train / Test Missing Indicators\n","trainM = Missing[idx[:Train_No],:]\n","testM = Missing[idx[Train_No:],:]\n","FindM = Missing[range(1000),:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6AhkOA-05kB","colab_type":"code","colab":{}},"source":["#%% Necessary Functions\n","\n","# 1. Xavier Initialization Definition\n","def xavier_init(size):\n","    in_dim = size[0]\n","    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n","    return tf.random_normal(shape = size, stddev = xavier_stddev)\n","    \n","# Hint Vector Generation\n","def sample_M(m, n, p):\n","    A = np.random.uniform(0., 1., size = [m, n])\n","    B = A > p\n","    C = 1.*B\n","    return C"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RM7RK_FB08-Q","colab_type":"code","colab":{}},"source":["'''\n","GAIN Consists of 3 Components\n","- Generator\n","- Discriminator\n","- Hint Mechanism\n","'''   \n","   \n","#%% GAIN Architecture   \n","   \n","#%% 1. Input Placeholders\n","# 1.1. Data Vector\n","X = tf.placeholder(tf.float32, shape = [None, Dim])\n","# 1.2. Mask Vector \n","M = tf.placeholder(tf.float32, shape = [None, Dim])\n","# 1.3. Hint vector\n","H = tf.placeholder(tf.float32, shape = [None, Dim])\n","# 1.4. X with missing values\n","New_X = tf.placeholder(tf.float32, shape = [None, Dim])\n","\n","#%% 2. Discriminator\n","D_W1 = tf.Variable(xavier_init([Dim*2, H_Dim1]))     # Data + Hint as inputs\n","D_b1 = tf.Variable(tf.zeros(shape = [H_Dim1]))\n","\n","D_W2 = tf.Variable(xavier_init([H_Dim1, H_Dim2]))\n","D_b2 = tf.Variable(tf.zeros(shape = [H_Dim2]))\n","\n","D_W3 = tf.Variable(xavier_init([H_Dim2, Dim]))\n","D_b3 = tf.Variable(tf.zeros(shape = [Dim]))       # Output is multi-variate\n","\n","theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n","\n","#%% 3. Generator\n","G_W1 = tf.Variable(xavier_init([Dim*2, H_Dim1]))     # Data + Mask as inputs (Random Noises are in Missing Components)\n","G_b1 = tf.Variable(tf.zeros(shape = [H_Dim1]))\n","\n","G_W2 = tf.Variable(xavier_init([H_Dim1, H_Dim2]))\n","G_b2 = tf.Variable(tf.zeros(shape = [H_Dim2]))\n","\n","G_W3 = tf.Variable(xavier_init([H_Dim2, Dim]))\n","G_b3 = tf.Variable(tf.zeros(shape = [Dim]))\n","\n","theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-wUqf7t1IIR","colab_type":"code","colab":{}},"source":["#%% GAIN Function\n","\n","#%% 1. Generator\n","def generator(new_x,m):\n","    inputs = tf.concat(axis = 1, values = [new_x,m])  # Mask + Data Concatenate\n","    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n","    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)   \n","    G_prob = tf.nn.sigmoid(tf.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n","    \n","    return G_prob\n","    \n","#%% 2. Discriminator\n","def discriminator(new_x, h):\n","    inputs = tf.concat(axis = 1, values = [new_x,h])  # Hint + Data Concatenate\n","    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)  \n","    D_h2 = tf.nn.relu(tf.matmul(D_h1, D_W2) + D_b2)\n","    D_logit = tf.matmul(D_h2, D_W3) + D_b3\n","    D_prob = tf.nn.sigmoid(D_logit)  # [0,1] Probability Output\n","    \n","    return D_prob\n","\n","#%% 3. Other functions\n","# Random sample generator for Z\n","def sample_Z(m, n):\n","    return np.random.uniform(0., 0.01, size = [m, n])        \n","\n","# Mini-batch generation\n","def sample_idx(m, n):\n","    A = np.random.permutation(m)\n","    idx = A[:n]\n","    return idx\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IohrX1Jd1Nt5","colab_type":"code","outputId":"307b648e-05a2-4a87-a885-128571c848f0","executionInfo":{"status":"ok","timestamp":1581597750195,"user_tz":-330,"elapsed":28290,"user":{"displayName":"Arun Pandian R","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCH0GbqS4vWSqatMz6fQZ8tXDeKF5M-eOUqMVUPpg=s64","userId":"07597072252487905646"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#%% Structure\n","# Generator\n","G_sample = generator(New_X,M)\n","\n","# Combine with original data\n","Hat_New_X = New_X * M + G_sample * (1-M)\n","\n","# Discriminator\n","D_prob = discriminator(Hat_New_X, H)\n","\n","#%% Loss\n","D_loss1 = -tf.reduce_mean(M * tf.log(D_prob + 1e-8) + (1-M) * tf.log(1. - D_prob + 1e-8)) \n","G_loss1 = -tf.reduce_mean((1-M) * tf.log(D_prob + 1e-8))\n","MSE_train_loss = tf.reduce_mean((M * New_X - M * G_sample)**2) / tf.reduce_mean(M)\n","\n","D_loss = D_loss1\n","G_loss = G_loss1 + alpha * MSE_train_loss \n","\n","#%% MSE Performance metric\n","MSE_test_loss = tf.reduce_mean(((1-M) * X - (1-M)*G_sample)**2) / tf.reduce_mean(1-M)\n","\n","#%% Solver\n","D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n","G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)\n","\n","# Sessions\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","#%% Iterations\n","\n","#%% Start Iterations\n","for it in tqdm(range(5000)):    \n","    \n","    #%% Inputs\n","    mb_idx = sample_idx(Train_No, mb_size)\n","    X_mb = trainX[mb_idx,:]  \n","    \n","    Z_mb = sample_Z(mb_size, Dim) \n","    M_mb = trainM[mb_idx,:]  \n","    H_mb1 = sample_M(mb_size, Dim, 1-p_hint)\n","    H_mb = M_mb * H_mb1\n","    \n","    New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n","    \n","    _, D_loss_curr = sess.run([D_solver, D_loss1], feed_dict = {M: M_mb, New_X: New_X_mb, H: H_mb})\n","    _, G_loss_curr, MSE_train_loss_curr, MSE_test_loss_curr = sess.run([G_solver, G_loss1, MSE_train_loss, MSE_test_loss],\n","                                                                       feed_dict = {X: X_mb, M: M_mb, New_X: New_X_mb, H: H_mb})\n","            \n","        \n","    #%% Intermediate Losses\n","    if it % 100 == 0:\n","        print('Iter: {}'.format(it))\n","        print('Train_loss: {:.4}'.format(np.sqrt(MSE_train_loss_curr)))\n","        print('Test_loss: {:.4}'.format(np.sqrt(MSE_test_loss_curr)))\n","        print()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  0%|          | 21/5000 [00:00<13:17,  6.25it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 0\n","Train_loss: 0.3048\n","Test_loss: 0.3028\n","\n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 120/5000 [00:00<02:32, 32.02it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 100\n","Train_loss: 0.1112\n","Test_loss: 0.1133\n","\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|▍         | 236/5000 [00:01<00:40, 118.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 200\n","Train_loss: 0.1019\n","Test_loss: 0.1076\n","\n"],"name":"stdout"},{"output_type":"stream","text":["  7%|▋         | 332/5000 [00:01<00:27, 168.91it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 300\n","Train_loss: 0.09661\n","Test_loss: 0.103\n","\n"],"name":"stdout"},{"output_type":"stream","text":["  9%|▊         | 431/5000 [00:02<00:24, 187.48it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 400\n","Train_loss: 0.08797\n","Test_loss: 0.09039\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 11%|█         | 529/5000 [00:03<00:23, 189.91it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 500\n","Train_loss: 0.08274\n","Test_loss: 0.08664\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 13%|█▎        | 626/5000 [00:03<00:23, 183.69it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 600\n","Train_loss: 0.07568\n","Test_loss: 0.0849\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 14%|█▍        | 723/5000 [00:04<00:22, 188.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 700\n","Train_loss: 0.07574\n","Test_loss: 0.07913\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|█▋        | 820/5000 [00:04<00:21, 190.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 800\n","Train_loss: 0.07301\n","Test_loss: 0.08169\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 18%|█▊        | 920/5000 [00:05<00:21, 185.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 900\n","Train_loss: 0.07112\n","Test_loss: 0.08107\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 21%|██        | 1041/5000 [00:05<00:20, 194.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1000\n","Train_loss: 0.06563\n","Test_loss: 0.07809\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 22%|██▏       | 1122/5000 [00:06<00:20, 191.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1100\n","Train_loss: 0.06601\n","Test_loss: 0.07334\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|██▍       | 1239/5000 [00:06<00:19, 189.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1200\n","Train_loss: 0.06427\n","Test_loss: 0.07585\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 27%|██▋       | 1340/5000 [00:07<00:18, 194.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1300\n","Train_loss: 0.06503\n","Test_loss: 0.07956\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 28%|██▊       | 1421/5000 [00:07<00:18, 193.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1400\n","Train_loss: 0.06242\n","Test_loss: 0.07165\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|███       | 1523/5000 [00:08<00:18, 188.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1500\n","Train_loss: 0.06212\n","Test_loss: 0.07209\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 32%|███▏      | 1623/5000 [00:08<00:17, 190.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1600\n","Train_loss: 0.06358\n","Test_loss: 0.0744\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 34%|███▍      | 1722/5000 [00:09<00:17, 184.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1700\n","Train_loss: 0.05972\n","Test_loss: 0.0714\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 37%|███▋      | 1838/5000 [00:09<00:16, 187.28it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1800\n","Train_loss: 0.05422\n","Test_loss: 0.06904\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 39%|███▊      | 1933/5000 [00:10<00:16, 187.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1900\n","Train_loss: 0.05588\n","Test_loss: 0.06811\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 41%|████      | 2028/5000 [00:10<00:16, 183.84it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2000\n","Train_loss: 0.05655\n","Test_loss: 0.07179\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 42%|████▏     | 2124/5000 [00:11<00:15, 185.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2100\n","Train_loss: 0.05751\n","Test_loss: 0.07075\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 44%|████▍     | 2223/5000 [00:12<00:14, 187.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2200\n","Train_loss: 0.05815\n","Test_loss: 0.0741\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 46%|████▋     | 2322/5000 [00:12<00:13, 193.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2300\n","Train_loss: 0.05655\n","Test_loss: 0.06953\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 48%|████▊     | 2422/5000 [00:13<00:13, 191.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2400\n","Train_loss: 0.05372\n","Test_loss: 0.06681\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|█████     | 2519/5000 [00:13<00:14, 174.93it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2500\n","Train_loss: 0.05147\n","Test_loss: 0.06801\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 53%|█████▎    | 2633/5000 [00:14<00:12, 184.83it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2600\n","Train_loss: 0.05205\n","Test_loss: 0.06658\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|█████▍    | 2729/5000 [00:14<00:12, 186.93it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2700\n","Train_loss: 0.04957\n","Test_loss: 0.06243\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 56%|█████▋    | 2824/5000 [00:15<00:11, 183.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2800\n","Train_loss: 0.05128\n","Test_loss: 0.06781\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 58%|█████▊    | 2922/5000 [00:15<00:10, 189.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2900\n","Train_loss: 0.05071\n","Test_loss: 0.06815\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 61%|██████    | 3039/5000 [00:16<00:10, 187.78it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3000\n","Train_loss: 0.05111\n","Test_loss: 0.06531\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 63%|██████▎   | 3136/5000 [00:16<00:10, 181.91it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3100\n","Train_loss: 0.05172\n","Test_loss: 0.06607\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|██████▍   | 3234/5000 [00:17<00:09, 190.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3200\n","Train_loss: 0.05004\n","Test_loss: 0.06512\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 3334/5000 [00:17<00:08, 194.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3300\n","Train_loss: 0.05076\n","Test_loss: 0.06681\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 69%|██████▊   | 3435/5000 [00:18<00:07, 196.28it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3400\n","Train_loss: 0.05057\n","Test_loss: 0.06738\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 71%|███████   | 3541/5000 [00:19<00:07, 200.93it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3500\n","Train_loss: 0.04945\n","Test_loss: 0.06538\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 72%|███████▏  | 3624/5000 [00:19<00:06, 197.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3600\n","Train_loss: 0.04757\n","Test_loss: 0.06546\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 74%|███████▍  | 3723/5000 [00:20<00:06, 187.83it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3700\n","Train_loss: 0.04895\n","Test_loss: 0.06464\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 76%|███████▋  | 3822/5000 [00:20<00:06, 189.66it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3800\n","Train_loss: 0.04829\n","Test_loss: 0.06981\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 78%|███████▊  | 3921/5000 [00:21<00:05, 192.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3900\n","Train_loss: 0.04746\n","Test_loss: 0.06696\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|████████  | 4023/5000 [00:21<00:05, 194.44it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4000\n","Train_loss: 0.0472\n","Test_loss: 0.06391\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 83%|████████▎ | 4129/5000 [00:22<00:04, 202.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4100\n","Train_loss: 0.04531\n","Test_loss: 0.06292\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|████████▍ | 4230/5000 [00:22<00:03, 193.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4200\n","Train_loss: 0.0482\n","Test_loss: 0.07004\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 87%|████████▋ | 4330/5000 [00:23<00:03, 191.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4300\n","Train_loss: 0.04629\n","Test_loss: 0.06319\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 89%|████████▊ | 4431/5000 [00:23<00:02, 196.21it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4400\n","Train_loss: 0.04633\n","Test_loss: 0.06399\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 91%|█████████ | 4531/5000 [00:24<00:02, 186.55it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4500\n","Train_loss: 0.04357\n","Test_loss: 0.0601\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 93%|█████████▎| 4631/5000 [00:24<00:01, 187.32it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4600\n","Train_loss: 0.0451\n","Test_loss: 0.06675\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|█████████▍| 4731/5000 [00:25<00:01, 195.72it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4700\n","Train_loss: 0.04519\n","Test_loss: 0.06755\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 97%|█████████▋| 4835/5000 [00:25<00:00, 199.96it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4800\n","Train_loss: 0.04696\n","Test_loss: 0.06997\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 99%|█████████▊| 4937/5000 [00:26<00:00, 194.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4900\n","Train_loss: 0.04823\n","Test_loss: 0.06877\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 5000/5000 [00:26<00:00, 187.82it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-Ig6_qPC1RRq","colab_type":"code","outputId":"51a1c18d-0bab-43af-df68-32bb6f61bf5f","executionInfo":{"status":"ok","timestamp":1581597755023,"user_tz":-330,"elapsed":1024,"user":{"displayName":"Arun Pandian R","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCH0GbqS4vWSqatMz6fQZ8tXDeKF5M-eOUqMVUPpg=s64","userId":"07597072252487905646"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#%% Final Loss\n","    \n","Z_mb = sample_Z(Test_No, Dim) \n","M_mb = testM\n","X_mb = testX\n","        \n","New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n","    \n","MSE_final, Sample = sess.run([MSE_test_loss, G_sample], feed_dict = {X: testX, M: testM, New_X: New_X_mb})\n","        \n","print('Final Test RMSE: ' + str(np.sqrt(MSE_final)))\n","print('MSE_final :'+ str(MSE_final))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Final Test RMSE: 0.06606924\n","MSE_final :0.004365144\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RB67CazJB4up","colab_type":"code","colab":{}},"source":["Z_mb = sample_Z(1000, Dim) \n","M_mb = FindM\n","X_mb = FindX\n","        \n","New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  \n","\n","MSE_final, Sample = sess.run([MSE_test_loss,G_sample], feed_dict={X:FindX, M:FindM, New_X:New_X_mb})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ytLzGsjj7uuO","colab_type":"code","outputId":"1eac1f72-4e28-4309-a031-d1aafe4805e2","executionInfo":{"status":"ok","timestamp":1581597762199,"user_tz":-330,"elapsed":1032,"user":{"displayName":"Arun Pandian R","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCH0GbqS4vWSqatMz6fQZ8tXDeKF5M-eOUqMVUPpg=s64","userId":"07597072252487905646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print('MSE_final:',MSE_final)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["MSE_final: 0.004385712\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NGOELG6P-Yah","colab_type":"code","colab":{}},"source":["df_result = pd.DataFrame(Sample)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_Gf76Pl_T5V","colab_type":"code","outputId":"bef36b59-2efa-4c74-eef8-e7cdceb90d6c","executionInfo":{"status":"ok","timestamp":1581597770089,"user_tz":-330,"elapsed":867,"user":{"displayName":"Arun Pandian R","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCH0GbqS4vWSqatMz6fQZ8tXDeKF5M-eOUqMVUPpg=s64","userId":"07597072252487905646"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["df_result.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.820090</td>\n","      <td>0.843513</td>\n","      <td>0.000064</td>\n","      <td>0.701050</td>\n","      <td>0.634487</td>\n","      <td>0.815988</td>\n","      <td>0.000068</td>\n","      <td>0.862313</td>\n","      <td>0.746239</td>\n","      <td>0.678159</td>\n","      <td>0.819459</td>\n","      <td>0.865113</td>\n","      <td>0.891317</td>\n","      <td>0.855594</td>\n","      <td>0.794654</td>\n","      <td>0.715432</td>\n","      <td>0.766756</td>\n","      <td>0.000025</td>\n","      <td>0.903258</td>\n","      <td>0.851522</td>\n","      <td>0.719812</td>\n","      <td>0.798933</td>\n","      <td>0.747489</td>\n","      <td>0.000020</td>\n","      <td>0.808827</td>\n","      <td>0.686500</td>\n","      <td>0.803351</td>\n","      <td>0.754369</td>\n","      <td>0.000003</td>\n","      <td>0.834011</td>\n","      <td>0.715532</td>\n","      <td>0.753040</td>\n","      <td>0.729193</td>\n","      <td>0.807312</td>\n","      <td>0.815070</td>\n","      <td>0.722472</td>\n","      <td>0.729694</td>\n","      <td>0.770726</td>\n","      <td>0.734808</td>\n","      <td>0.718324</td>\n","      <td>0.642093</td>\n","      <td>0.000009</td>\n","      <td>0.847923</td>\n","      <td>0.755742</td>\n","      <td>0.727122</td>\n","      <td>0.735410</td>\n","      <td>0.000061</td>\n","      <td>0.794741</td>\n","      <td>0.777937</td>\n","      <td>0.694893</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.823452</td>\n","      <td>0.856092</td>\n","      <td>0.000093</td>\n","      <td>0.795144</td>\n","      <td>0.741963</td>\n","      <td>0.821993</td>\n","      <td>0.000093</td>\n","      <td>0.888440</td>\n","      <td>0.822228</td>\n","      <td>0.774060</td>\n","      <td>0.824805</td>\n","      <td>0.880366</td>\n","      <td>0.904690</td>\n","      <td>0.875927</td>\n","      <td>0.798487</td>\n","      <td>0.714896</td>\n","      <td>0.782615</td>\n","      <td>0.000029</td>\n","      <td>0.848787</td>\n","      <td>0.768369</td>\n","      <td>0.725869</td>\n","      <td>0.776938</td>\n","      <td>0.697505</td>\n","      <td>0.000025</td>\n","      <td>0.693922</td>\n","      <td>0.673797</td>\n","      <td>0.755861</td>\n","      <td>0.697287</td>\n","      <td>0.000005</td>\n","      <td>0.790397</td>\n","      <td>0.721711</td>\n","      <td>0.734393</td>\n","      <td>0.713866</td>\n","      <td>0.796328</td>\n","      <td>0.821375</td>\n","      <td>0.706102</td>\n","      <td>0.729700</td>\n","      <td>0.808201</td>\n","      <td>0.819948</td>\n","      <td>0.828490</td>\n","      <td>0.633798</td>\n","      <td>0.000012</td>\n","      <td>0.853833</td>\n","      <td>0.777414</td>\n","      <td>0.778374</td>\n","      <td>0.710593</td>\n","      <td>0.000085</td>\n","      <td>0.777219</td>\n","      <td>0.770541</td>\n","      <td>0.686325</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.883087</td>\n","      <td>0.905930</td>\n","      <td>0.000059</td>\n","      <td>0.798744</td>\n","      <td>0.727814</td>\n","      <td>0.864398</td>\n","      <td>0.000052</td>\n","      <td>0.918069</td>\n","      <td>0.836872</td>\n","      <td>0.764872</td>\n","      <td>0.850504</td>\n","      <td>0.895065</td>\n","      <td>0.915729</td>\n","      <td>0.895866</td>\n","      <td>0.830004</td>\n","      <td>0.673789</td>\n","      <td>0.751432</td>\n","      <td>0.000015</td>\n","      <td>0.905122</td>\n","      <td>0.840408</td>\n","      <td>0.652387</td>\n","      <td>0.786047</td>\n","      <td>0.784360</td>\n","      <td>0.000011</td>\n","      <td>0.850554</td>\n","      <td>0.675807</td>\n","      <td>0.819227</td>\n","      <td>0.834311</td>\n","      <td>0.000001</td>\n","      <td>0.885547</td>\n","      <td>0.704009</td>\n","      <td>0.718564</td>\n","      <td>0.763122</td>\n","      <td>0.873767</td>\n","      <td>0.878303</td>\n","      <td>0.658788</td>\n","      <td>0.677862</td>\n","      <td>0.744310</td>\n","      <td>0.790042</td>\n","      <td>0.792120</td>\n","      <td>0.633979</td>\n","      <td>0.000006</td>\n","      <td>0.823872</td>\n","      <td>0.773836</td>\n","      <td>0.744973</td>\n","      <td>0.671797</td>\n","      <td>0.000065</td>\n","      <td>0.777925</td>\n","      <td>0.780040</td>\n","      <td>0.730865</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.862252</td>\n","      <td>0.874077</td>\n","      <td>0.000266</td>\n","      <td>0.745865</td>\n","      <td>0.686151</td>\n","      <td>0.842486</td>\n","      <td>0.000264</td>\n","      <td>0.871320</td>\n","      <td>0.763996</td>\n","      <td>0.704912</td>\n","      <td>0.847493</td>\n","      <td>0.876687</td>\n","      <td>0.868806</td>\n","      <td>0.796248</td>\n","      <td>0.721717</td>\n","      <td>0.745354</td>\n","      <td>0.759850</td>\n","      <td>0.000083</td>\n","      <td>0.752837</td>\n","      <td>0.639869</td>\n","      <td>0.761839</td>\n","      <td>0.818367</td>\n","      <td>0.735587</td>\n","      <td>0.000052</td>\n","      <td>0.672589</td>\n","      <td>0.749882</td>\n","      <td>0.839821</td>\n","      <td>0.794948</td>\n","      <td>0.000014</td>\n","      <td>0.741363</td>\n","      <td>0.695057</td>\n","      <td>0.682268</td>\n","      <td>0.714793</td>\n","      <td>0.793743</td>\n","      <td>0.770496</td>\n","      <td>0.626791</td>\n","      <td>0.682603</td>\n","      <td>0.747304</td>\n","      <td>0.760629</td>\n","      <td>0.754771</td>\n","      <td>0.620511</td>\n","      <td>0.000040</td>\n","      <td>0.822608</td>\n","      <td>0.759370</td>\n","      <td>0.727194</td>\n","      <td>0.658631</td>\n","      <td>0.000233</td>\n","      <td>0.781292</td>\n","      <td>0.789232</td>\n","      <td>0.708639</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.783630</td>\n","      <td>0.818613</td>\n","      <td>0.000093</td>\n","      <td>0.758755</td>\n","      <td>0.705046</td>\n","      <td>0.772416</td>\n","      <td>0.000091</td>\n","      <td>0.850510</td>\n","      <td>0.790899</td>\n","      <td>0.743137</td>\n","      <td>0.791865</td>\n","      <td>0.838946</td>\n","      <td>0.870163</td>\n","      <td>0.850621</td>\n","      <td>0.790261</td>\n","      <td>0.706429</td>\n","      <td>0.755177</td>\n","      <td>0.000046</td>\n","      <td>0.849781</td>\n","      <td>0.784521</td>\n","      <td>0.733623</td>\n","      <td>0.791264</td>\n","      <td>0.731541</td>\n","      <td>0.000038</td>\n","      <td>0.758917</td>\n","      <td>0.702330</td>\n","      <td>0.784153</td>\n","      <td>0.727406</td>\n","      <td>0.000006</td>\n","      <td>0.806643</td>\n","      <td>0.681056</td>\n","      <td>0.671948</td>\n","      <td>0.662231</td>\n","      <td>0.779493</td>\n","      <td>0.797918</td>\n","      <td>0.636165</td>\n","      <td>0.649217</td>\n","      <td>0.709718</td>\n","      <td>0.747294</td>\n","      <td>0.757286</td>\n","      <td>0.598484</td>\n","      <td>0.000016</td>\n","      <td>0.810123</td>\n","      <td>0.751295</td>\n","      <td>0.735282</td>\n","      <td>0.669242</td>\n","      <td>0.000094</td>\n","      <td>0.770103</td>\n","      <td>0.758730</td>\n","      <td>0.690198</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         0         1         2   ...        47        48        49\n","0  0.820090  0.843513  0.000064  ...  0.794741  0.777937  0.694893\n","1  0.823452  0.856092  0.000093  ...  0.777219  0.770541  0.686325\n","2  0.883087  0.905930  0.000059  ...  0.777925  0.780040  0.730865\n","3  0.862252  0.874077  0.000266  ...  0.781292  0.789232  0.708639\n","4  0.783630  0.818613  0.000093  ...  0.770103  0.758730  0.690198\n","\n","[5 rows x 50 columns]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"Mf5J0CwrC-Su","colab_type":"code","outputId":"5a7b10ee-60fa-4193-f054-1bb56675c455","executionInfo":{"status":"ok","timestamp":1581505418891,"user_tz":-330,"elapsed":1239,"user":{"displayName":"Arun Pandian R","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCH0GbqS4vWSqatMz6fQZ8tXDeKF5M-eOUqMVUPpg=s64","userId":"07597072252487905646"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["actual_df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.39325</td>\n","      <td>-0.58336</td>\n","      <td>-0.47175</td>\n","      <td>-0.51374</td>\n","      <td>-0.49806</td>\n","      <td>-0.38474</td>\n","      <td>-0.50544</td>\n","      <td>-0.45865</td>\n","      <td>-0.48011</td>\n","      <td>-0.49821</td>\n","      <td>-0.44725</td>\n","      <td>-0.53410</td>\n","      <td>-0.54686</td>\n","      <td>-0.48339</td>\n","      <td>-0.49871</td>\n","      <td>-0.47177</td>\n","      <td>-0.52128</td>\n","      <td>-0.57743</td>\n","      <td>-0.48199</td>\n","      <td>-0.57963</td>\n","      <td>-0.47891</td>\n","      <td>-0.50790</td>\n","      <td>-0.44786</td>\n","      <td>-0.40451</td>\n","      <td>-0.33950</td>\n","      <td>-0.54578</td>\n","      <td>-0.43843</td>\n","      <td>-0.50953</td>\n","      <td>-0.27542</td>\n","      <td>-0.21293</td>\n","      <td>-0.83023</td>\n","      <td>-0.56492</td>\n","      <td>-0.33589</td>\n","      <td>-0.33840</td>\n","      <td>-0.27590</td>\n","      <td>-1.07506</td>\n","      <td>-0.28629</td>\n","      <td>-0.21245</td>\n","      <td>-0.19798</td>\n","      <td>-0.21598</td>\n","      <td>-0.88088</td>\n","      <td>-0.53669</td>\n","      <td>-0.30754</td>\n","      <td>-0.29569</td>\n","      <td>-0.28139</td>\n","      <td>-0.73443</td>\n","      <td>-0.60668</td>\n","      <td>-0.37522</td>\n","      <td>-0.24987</td>\n","      <td>-0.22637</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.46394</td>\n","      <td>-0.55902</td>\n","      <td>-0.50768</td>\n","      <td>-0.56086</td>\n","      <td>-0.59995</td>\n","      <td>-0.43636</td>\n","      <td>-0.51445</td>\n","      <td>-0.49466</td>\n","      <td>-0.51900</td>\n","      <td>-0.61017</td>\n","      <td>-0.47843</td>\n","      <td>-0.51443</td>\n","      <td>-0.55461</td>\n","      <td>-0.52448</td>\n","      <td>-0.55597</td>\n","      <td>-0.45817</td>\n","      <td>-0.53070</td>\n","      <td>-0.58489</td>\n","      <td>-0.48573</td>\n","      <td>-0.57592</td>\n","      <td>-0.47383</td>\n","      <td>-0.48221</td>\n","      <td>-0.44337</td>\n","      <td>-0.39221</td>\n","      <td>-0.32945</td>\n","      <td>-0.55203</td>\n","      <td>-0.45594</td>\n","      <td>-0.47436</td>\n","      <td>-0.29060</td>\n","      <td>-0.21293</td>\n","      <td>-0.73171</td>\n","      <td>-0.57603</td>\n","      <td>-0.35809</td>\n","      <td>-0.32698</td>\n","      <td>-0.26483</td>\n","      <td>-1.11513</td>\n","      <td>-0.22032</td>\n","      <td>-0.23385</td>\n","      <td>-0.20568</td>\n","      <td>-0.20430</td>\n","      <td>-0.96510</td>\n","      <td>-0.58501</td>\n","      <td>-0.26755</td>\n","      <td>-0.24605</td>\n","      <td>-0.23469</td>\n","      <td>-0.75008</td>\n","      <td>-0.67076</td>\n","      <td>-0.38356</td>\n","      <td>-0.27873</td>\n","      <td>-0.23883</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.45185</td>\n","      <td>-0.54247</td>\n","      <td>-0.53390</td>\n","      <td>-0.63754</td>\n","      <td>-0.64403</td>\n","      <td>-0.45964</td>\n","      <td>-0.49543</td>\n","      <td>-0.51646</td>\n","      <td>-0.58449</td>\n","      <td>-0.67248</td>\n","      <td>-0.49261</td>\n","      <td>-0.51050</td>\n","      <td>-0.57957</td>\n","      <td>-0.57584</td>\n","      <td>-0.63996</td>\n","      <td>-0.48083</td>\n","      <td>-0.51500</td>\n","      <td>-0.57246</td>\n","      <td>-0.51376</td>\n","      <td>-0.60658</td>\n","      <td>-0.50838</td>\n","      <td>-0.48418</td>\n","      <td>-0.43350</td>\n","      <td>-0.40890</td>\n","      <td>-0.32670</td>\n","      <td>-0.58329</td>\n","      <td>-0.46761</td>\n","      <td>-0.39597</td>\n","      <td>-0.30375</td>\n","      <td>-0.20317</td>\n","      <td>-0.69556</td>\n","      <td>-0.55380</td>\n","      <td>-0.38129</td>\n","      <td>-0.33225</td>\n","      <td>-0.24637</td>\n","      <td>-0.98382</td>\n","      <td>-0.10461</td>\n","      <td>-0.26677</td>\n","      <td>-0.25956</td>\n","      <td>-0.23306</td>\n","      <td>-1.02326</td>\n","      <td>-0.57026</td>\n","      <td>-0.23357</td>\n","      <td>-0.23214</td>\n","      <td>-0.22352</td>\n","      <td>-0.76885</td>\n","      <td>-0.67498</td>\n","      <td>-0.42529</td>\n","      <td>-0.30086</td>\n","      <td>-0.25460</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.46859</td>\n","      <td>-0.50743</td>\n","      <td>-0.52905</td>\n","      <td>-0.65972</td>\n","      <td>-0.69890</td>\n","      <td>-0.44648</td>\n","      <td>-0.47741</td>\n","      <td>-0.52404</td>\n","      <td>-0.62338</td>\n","      <td>-0.70363</td>\n","      <td>-0.51151</td>\n","      <td>-0.49673</td>\n","      <td>-0.56838</td>\n","      <td>-0.59639</td>\n","      <td>-0.68578</td>\n","      <td>-0.44729</td>\n","      <td>-0.48046</td>\n","      <td>-0.56749</td>\n","      <td>-0.52871</td>\n","      <td>-0.61494</td>\n","      <td>-0.53075</td>\n","      <td>-0.48517</td>\n","      <td>-0.43799</td>\n","      <td>-0.41066</td>\n","      <td>-0.32122</td>\n","      <td>-0.56766</td>\n","      <td>-0.45789</td>\n","      <td>-0.34774</td>\n","      <td>-0.30982</td>\n","      <td>-0.21683</td>\n","      <td>-0.67477</td>\n","      <td>-0.56399</td>\n","      <td>-0.42264</td>\n","      <td>-0.33752</td>\n","      <td>-0.25744</td>\n","      <td>-0.86956</td>\n","      <td>-0.17824</td>\n","      <td>-0.31203</td>\n","      <td>-0.26555</td>\n","      <td>-0.26092</td>\n","      <td>-0.97914</td>\n","      <td>-0.51457</td>\n","      <td>-0.18858</td>\n","      <td>-0.17257</td>\n","      <td>-0.17073</td>\n","      <td>-0.72087</td>\n","      <td>-0.64547</td>\n","      <td>-0.44115</td>\n","      <td>-0.31144</td>\n","      <td>-0.25709</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.46208</td>\n","      <td>-0.47238</td>\n","      <td>-0.49991</td>\n","      <td>-0.64955</td>\n","      <td>-0.73710</td>\n","      <td>-0.47887</td>\n","      <td>-0.44337</td>\n","      <td>-0.53730</td>\n","      <td>-0.63566</td>\n","      <td>-0.70752</td>\n","      <td>-0.49828</td>\n","      <td>-0.48787</td>\n","      <td>-0.53740</td>\n","      <td>-0.60853</td>\n","      <td>-0.67241</td>\n","      <td>-0.38744</td>\n","      <td>-0.44122</td>\n","      <td>-0.57495</td>\n","      <td>-0.55207</td>\n","      <td>-0.61773</td>\n","      <td>-0.50330</td>\n","      <td>-0.46837</td>\n","      <td>-0.45055</td>\n","      <td>-0.42120</td>\n","      <td>-0.29745</td>\n","      <td>-0.59892</td>\n","      <td>-0.46956</td>\n","      <td>-0.30653</td>\n","      <td>-0.30578</td>\n","      <td>-0.22561</td>\n","      <td>-0.59704</td>\n","      <td>-0.58066</td>\n","      <td>-0.45089</td>\n","      <td>-0.32610</td>\n","      <td>-0.27405</td>\n","      <td>-0.70328</td>\n","      <td>-0.31976</td>\n","      <td>-0.33919</td>\n","      <td>-0.27239</td>\n","      <td>-0.29418</td>\n","      <td>-0.93603</td>\n","      <td>-0.43104</td>\n","      <td>-0.15260</td>\n","      <td>-0.15370</td>\n","      <td>-0.17073</td>\n","      <td>-0.71148</td>\n","      <td>-0.60162</td>\n","      <td>-0.45283</td>\n","      <td>-0.33261</td>\n","      <td>-0.25793</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         1        2        3        4  ...       47       48       49       50\n","0 -0.39325 -0.58336 -0.47175 -0.51374  ... -0.60668 -0.37522 -0.24987 -0.22637\n","1 -0.46394 -0.55902 -0.50768 -0.56086  ... -0.67076 -0.38356 -0.27873 -0.23883\n","2 -0.45185 -0.54247 -0.53390 -0.63754  ... -0.67498 -0.42529 -0.30086 -0.25460\n","3 -0.46859 -0.50743 -0.52905 -0.65972  ... -0.64547 -0.44115 -0.31144 -0.25709\n","4 -0.46208 -0.47238 -0.49991 -0.64955  ... -0.60162 -0.45283 -0.33261 -0.25793\n","\n","[5 rows x 50 columns]"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"EiawvR7xDS-U","colab_type":"code","colab":{}},"source":["df_result.to_excel('/content/drive/My Drive/piv-project/GAIN-Pressure-Result.xlsx', header=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6y3wln-aGLpH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}